{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import proposed_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from callbacks import Step\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('AGG')\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shap\n",
    "import keras.backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(lines,img_path,inputH,inputW,train=True):\n",
    "    imagew = 128\n",
    "    imageh = 128\n",
    "    num = len(lines)\n",
    "    batch = np.zeros((num, imagew, imageh,1), dtype='float32')\n",
    "\n",
    "\n",
    "    labels = np.zeros(num, dtype='int')\n",
    "    for i in range(num):\n",
    "        path = lines[i].split(' ')[0]\n",
    "        label = lines[i].split(' ')[-1]\n",
    "\n",
    "        label = label.strip('\\n')\n",
    "        label = int(label)\n",
    "\n",
    "        img = path\n",
    "\n",
    "        if train:\n",
    "            #crop_x = random.randint(0, np.max([0, imagew-inputW]))\n",
    "            #crop_y = random.randint(0, np.max([0, imageh-inputH]))\n",
    "            #is_flip = random.randint(0, 1)\n",
    "\n",
    "            try:\n",
    "                image = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(img)\n",
    "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            #image = image[crop_y:crop_y + inputH, crop_x:crop_x + inputW]\n",
    "            image = cv2.resize(image, (imagew, imageh))\n",
    "\n",
    "            #if is_flip == 1:\n",
    "            #    image = cv2.flip(image, 1)\n",
    "\n",
    "            batch[i,:,:,0] = image\n",
    "            labels[i] = label\n",
    "        else:\n",
    "            image = cv2.imread(img,cv2.IMREAD_GRAYSCALE)\n",
    "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "            #Hshmean = int(np.round(np.max([0, np.round((imageh-inputH)/2)])))\n",
    "            #Wshmean = int(np.round(np.max([0, np.round((imagew-inputW)/2)])))\n",
    "            #image = image[Hshmean:Hshmean+inputH,Wshmean:Wshmean+inputW]\n",
    "            image = cv2.resize(image, (imagew, imageh))\n",
    "\n",
    "            batch[i,:,:,0] = image\n",
    "            labels[i] = label\n",
    "\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir('MIT-BIH_AD/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['.DS_Store', 'N', '.ipynb_checkpoints', 'B']"
      ],
      "text/plain": [
       "['.DS_Store', 'N', '.ipynb_checkpoints', 'B']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "k=0\n",
    "for w in folders:\n",
    "    if w[0] == 'B' or w[0] == 'N':\n",
    "        for i in os.listdir('MIT-BIH_AD/'+w):\n",
    "            files.append('MIT-BIH_AD/'+w+'/'+i+' '+str(k))\n",
    "            k=k+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = int(0.8*len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(files)\n",
    "train_list = files[:l]\n",
    "val_list = files[l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_batch( t_list, batch_size, num_classes, img_path, inputH, inputW ):\n",
    "    num = len(t_list)\n",
    "    while True:\n",
    "        new_line = []\n",
    "        for m in range(num):\n",
    "            new_line.append(t_list[m])\n",
    "\n",
    "        for i in range(int(num/batch_size)):\n",
    "            a = i*batch_size\n",
    "            b = (i+1)*batch_size\n",
    "            x_train, x_labels = process_batch(new_line[a:b], img_path, inputH, inputW, train=True)\n",
    "            y = np_utils.to_categorical(np.array(x_labels), num_classes)\n",
    "            yield x_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_val_batch(v_list,batch_size,num_classes,img_path,inputH,inputW):\n",
    "    \n",
    "    num = len(v_list)\n",
    "    while True:\n",
    "        new_line = []\n",
    "        for m in range(num):\n",
    "            new_line.append(v_list[m])\n",
    "        for i in range(int(num / batch_size)):\n",
    "            a = i * batch_size\n",
    "            b = (i + 1) * batch_size\n",
    "            y_test,y_labels = process_batch(v_list[a:b],img_path,inputH,inputW,train=False)\n",
    "            y = np_utils.to_categorical(np.array(y_labels), num_classes)\n",
    "            yield y_test, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epochs = 1\n",
    "input_h = 96\n",
    "input_w = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 126, 126, 64)      640       \n",
      "_________________________________________________________________\n",
      "elu_17 (ELU)                 (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 126, 126, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 61, 61, 128)       73856     \n",
      "_________________________________________________________________\n",
      "elu_18 (ELU)                 (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 61, 61, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "_________________________________________________________________\n",
      "elu_19 (ELU)                 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "elu_20 (ELU)                 (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 13,218,306\n",
      "Trainable params: 13,216,898\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = proposed_model(nb_classes=num_classes)\n",
    "lr = 0.001\n",
    "adam = Adam(lr=lr)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "35/35 [==============================] - 100s 3s/step - loss: 1.1641 - accuracy: 0.5051 - val_loss: 97.7460 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "            generator_train_batch(train_list, batch_size, num_classes, '', input_h, input_w),\n",
    "            steps_per_epoch=len(train_list) // batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=[Step()],\n",
    "            validation_data=generator_val_batch(val_list, batch_size, num_classes, '', input_h, input_w),\n",
    "            validation_steps=len(val_list) // batch_size,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
